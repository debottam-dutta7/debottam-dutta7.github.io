<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Debottam Dutta</title> <meta name="author" content="Debottam Dutta"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://debottam-dutta7.github.io/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Debottam</span> Dutta </h1> <p class="desc">PhD Student @ <a href="https://sinrg.csl.illinois.edu/" target="_blank" rel="noopener noreferrer">SiNRG</a> | ECE, <a href="https://illinois.edu/" target="_blank" rel="noopener noreferrer">University of Illinois at Urbana-Champaign </a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 300px)" srcset="/assets/img/prof_pic-300.webp"></source> <source media="(max-width: 400px)" srcset="/assets/img/prof_pic-400.webp"></source> <source media="(max-width: 700px)" srcset="/assets/img/prof_pic-700.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg"> </picture> </figure> </div> <div class="clearfix"> <div style="text-align: justify"> <p> I am a 3rd year ECE PhD student at <a href="https://sinrg.csl.illinois.edu/" target="_blank" rel="noopener noreferrer"> Signals and Inference Research Group (SiNRG)</a> under the guidance of <a href="https://croy.web.engr.illinois.edu/" target="_blank" rel="noopener noreferrer"> Prof. Romit Roy Choudhury</a>. My research interests lie at the intersection of generative models and their applications to Audio and Images. </p> Prior to joining PhD, I worked as a Research Fellow at <a href="http://www.leap.ee.iisc.ac.in/" target="_blank" rel="noopener noreferrer"> LEAP Lab</a>, <a href="https://iisc.ac.in/" target="_blank" rel="noopener noreferrer">Indian Institute of Science </a> under <a href="http://leap.ee.iisc.ac.in/sriram/" target="_blank" rel="noopener noreferrer">Prof. Sriram Ganapathy</a>. During that time, I mostly focused on learning useful and interpretable audio representations tailored towards different downstream tasks. To know more about my work please visit <a href="https://debottam-dutta7.github.io/publications/">Publications</a>. </div> <p><br></p> </div> <div class="news"> <h3>News</h3> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Sep 30, 2024</th> <td> A paper got accepted at NeurIPS 2024 Workshop on AI-Driven Speech, Music, and Sound Generation. </td> </tr> <tr> <th scope="row">Jan 1, 2024</th> <td> Journal paper got accepted for TASLP. </td> </tr> <tr> <th scope="row">Jun 22, 2023</th> <td> Coswara dataset paper got accept at Nature Scientific data! </td> </tr> <tr> <th scope="row">Jun 15, 2022</th> <td> Two papers got accepted at Interspeech 2022. </td> </tr> <tr> <th scope="row">Jun 1, 2022</th> <td> <a class="news-title" href="/news/show_and_tell_coswara_accept/">Show and tell paper got accepted at Interspeech2022</a> </td> </tr> </table> </div> </div> <div class="publications"> <h3>Selected Publications</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">WASPAA</abbr></div> <div id="9632708" class="col-sm-8"> <div class="title">A Multi-Head Relevance Weighting Framework for Learning Raw Waveform Audio Representations</div> <div class="author"> <em>Debottam Dutta</em>, Purvi Agrawal, and Sriram Ganapathy </div> <div class="periodical"> <em>In 2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/multihead2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9632708</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dutta, Debottam and Agrawal, Purvi and Ganapathy, Sriram}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Multi-Head Relevance Weighting Framework for Learning Raw Waveform Audio Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{191-195}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/WASPAA52581.2021.9632708}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Interspeech</abbr></div> <div id="dutta22b_interspeech" class="col-sm-8"> <div class="title">Acoustic Representation Learning on Breathing and Speech Signals for COVID-19 Detection</div> <div class="author"> <em>Debottam Dutta</em>, Debarpan Bhattacharya, Sriram Ganapathy, Amir Hossein Poorjam, Deepak Mittal, and Maneesh Singh </div> <div class="periodical"> <em>In Proc. Interspeech 2022</em> 2022 </div> <div class="links"> <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/dutta22b_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Nature Sci. Data</abbr></div> <div id="Bhattacharya2023-ps" class="col-sm-8"> <div class="title">Coswara: A respiratory sounds and symptoms dataset for remote screening of SARS-CoV-2 infection</div> <div class="author">Debarpan Bhattacharya, Neeraj Kumar Sharma,  <em>Debottam Dutta</em>, Srikanth Raj Chetupalli, Pravin Mote, Sriram Ganapathy, C Chandrakiran, Sahiti Nori, K K Suhail, Sadhana Gonuguntla, and Murali Alagesan </div> <div class="periodical"> <em>Sci. Data</em> Jun 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41597-023-02266-0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>This paper presents the Coswara dataset, a dataset containing diverse set of respiratory sounds and rich meta-data, recorded between April-2020 and February-2022 from 2635 individuals (1819 SARS-CoV-2 negative, 674 positive, and 142 recovered subjects). The respiratory sounds contained nine sound categories associated with variants of breathing, cough and speech. The rich metadata contained demographic information associated with age, gender and geographic location, as well as the health information relating to the symptoms, pre-existing respiratory ailments, comorbidity and SARS-CoV-2 test status. Our study is the first of its kind to manually annotate the audio quality of the entire dataset (amounting to 65 hours) through manual listening. The paper summarizes the data collection procedure, demographic, symptoms and audio data information. A COVID-19 classifier based on bi-directional long short-term (BLSTM) architecture, is trained and evaluated on the different population sub-groups contained in the dataset to understand the bias/fairness of the model. This enabled the analysis of the impact of gender, geographic location, date of recording, and language proficiency on the COVID-19 detection performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Bhattacharya2023-ps</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coswara: A respiratory sounds and symptoms dataset for remote
                screening of {SARS-CoV-2} infection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bhattacharya, Debarpan and Sharma, Neeraj Kumar and Dutta, Debottam and Chetupalli, Srikanth Raj and Mote, Pravin and Ganapathy, Sriram and Chandrakiran, C and Nori, Sahiti and Suhail, K K and Gonuguntla, Sadhana and Alagesan, Murali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Sci. Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{397}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TASLP</abbr></div> <div id="10261213" class="col-sm-8"> <div class="title">Speech Dereverberation With Frequency Domain Autoregressive Modeling</div> <div class="author">Anurenjan Purushothaman,  <em>Debottam Dutta</em>, Rohit Kumar, and Sriram Ganapathy </div> <div class="periodical"> <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> Jun 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2309.13537" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10261213</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Purushothaman, Anurenjan and Dutta, Debottam and Kumar, Rohit and Ganapathy, Sriram}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Speech Dereverberation With Frequency Domain Autoregressive Modeling}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{32}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{29-38}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Frequency-domain analysis;Reverberation;Task analysis;Convolution;Predictive models;Mirrors;Analytical models;Dereverberation;end-to-end ASR;frequency domain auto-regressive modeling;joint modeling}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TASLP.2023.3317570}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Neurips</abbr></div> <div id="xu2024multisource" class="col-sm-8"> <div class="title">Multi-Source Music Generation with Latent Diffusion</div> <div class="author">Zhongweiyang Xu,  <em>Debottam Dutta</em>, Yu-Lin Wei, and Romit Roy Choudhury </div> <div class="periodical"> <em>In Audio Imagination: NeurIPS 2024 Workshop AI-Driven Speech, Music, and Sound Generation</em> Jun 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf/740a8c1a4bcef94c3ad6e58c52336c6703883ce2.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xu2024multisource</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Source Music Generation with Latent Diffusion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Zhongweiyang and Dutta, Debottam and Wei, Yu-Lin and Choudhury, Romit Roy}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Audio Imagination: NeurIPS 2024 Workshop AI-Driven Speech, Music, and Sound Generation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=bxzUnfWrgk}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%64%65%62%6F%74%74%61%6D.%64%75%74%74%61%37@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gBYk86YAAAAJ&amp;hl" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/debottam-dutta7" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/debottam-dutta" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Debottam Dutta. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>